{
  "hash": "2a5de599523ac413404fe26653702665",
  "result": {
    "markdown": "---\ntitle: \"Getting Started\"\ndate: last-modified\neditor_options: \n  markdown: \n    wrap: sentence\n---\n\nFor the first lesson, we'll set up the project we'll work in for the next several meetings.\nBy the end of today, we'll have:\n\n-   Set up a new Github repo\n-   Downloaded the data\n-   Explored and cleaned the data a bit\n-   Made a visualization\n\nAlong the way, we'll be using Quarto documents (successor to RMarkdown documents) so that our work is well-documented and ready to share.\nBefore we get started with all of that, though, let's familiarize ourselves with the data we'll be working with.\n\n## The Iowa DNR's Lake Monitoring Dataset\n\nFor the past several decades, the Iowa Department of Natural Resources has been monitoring the water quality of multiple beaches throughout Iowa in order to better understand harmful algal blooms.\nBetween Memorial and Labor day, weekly water samples are taken from these beaches and several chemical and biological measurements are taken.\nIn addition to these measurements, we will incorporate land-use classifications and weather data.\n\n![The beaches that the Iowa DNR collected water samples from in 2018.](../images/DNR_samples.jpg \"Title\"){fig-align=\"center\"}\n\nThe measurement of interest is the microcystin concentration, measured in ug/L.\nWhen this measurement is above the EPA-recommend 8 ug/L, the beach is closed as it is considered dangerous to humans at that point.\nHence, this is considered a **supervised** learning problem.\n\nThe goal of the project will be to use this data to:\n\n1.  Attempt to better understand what drives harmful algal blooms\n2.  Create a model that can predict harmful algal blooms\n\nNow that we know a little bit about the data we'll be working with and the problem we're being asked to solve, let's go ahead and set up our project.\n\n# Setting up your project directory\n\nWe'll start by creating a new Github repository.\nGo to [github](www.github.com) and click the `+` and create a new repository.\n\n1.  Name the repository `dnr_habs`.\n2.  Select the option to create a `README.md` file\n3.  Then click \"Create repository\".\n\n![](../images/new_git_repo.png){fig-align=\"center\" width=\"472\"}\n\nYou'll be taken to your new `dnr_habs` repository.\nClick on the \"Code\" button and you'll see the copy link for the repo with a couple different options.\nIf you've set up an SSH key, click `SSH`; otherwise, HTTPS is fine.\nClick the copy button to the right of the link:\n\n![](../images/git_copy_clone_link.png){fig-align=\"center\" width=\"800\"}\n\nNow open your command line interface (CLI).\nOn Mac, this can be Terminal or iTerm2; on Windows, this can be Git Bash or PuTTy.\nNavigate to wherever you want your project to sit and run the following command:\n\n    git clone https://github.com/pommevilla/dnr_habs.git\n\nYou'll now see that `dnr_habs` is on your computer now.\n\n::: {.callout-note appearance=\"simple\"}\n## Keep your project directories in one place!\n\nIf you haven't done so already, I highly recommend keeping all of your project repositories in a central place.\nFor example, on all my machines, I have a `repos` folder in my home directory.\nThis way, whenever I'm doing stuff on command line, I know that all of my work can be found within `~/repos`.\n\nI also keep a directory called `scratch` here that contains all of the one-off random tasks/scripts I find myself writing.\nWhenever I need to do a random plot or calculation that doesn't need it's own project, I just throw it in `scratch` instead of cluttering up my Desktop or somewhere else.\nThis way, I always know where to look for these things if I need to reference it later.\n:::\n\n# Get the data\n\nCreate a folder in `dnr_habs` called `data`.\nYou can download a zip of the data we'll use from [this link](https://github.com/pommevilla/germs.dsc/raw/main/data/DNR_data.zip).\nSave `DNR_data.zip` to the `data` folder.\n\nNow that we've made a change, let's go ahead and make our first commit.\nOn the command line:\n\n1.  Run `git status` to verify that the only thing that's changed is adding `data/DNR_data.zip`\n2.  Run `git add data/DNR_data.zip` to stage the data\n3.  Run `git commit -m 'Initial add of data'` to commit the changes\n4.  Send the changes to the remote using `git push`\n\nNow, if you go back to your remote repository, you should see that the `data` folder is viewable.\n\n::: {.callout-note appearance=\"simple\"}\n## A word about `git status`\n\nI didn't show it up above, but I run `git status` after nearly every `git` command I do to make sure that what I expect to happen is actually happening.\nIt might be slightly annoying to do all the time, but the couple of seconds you take running `git status` will prevent hours of headaches down the road when you know what to look for.\n:::\n\n# Create a project in RStudio\n\nOpen up RStudio and select `File > New Project > Existing Directory`, then use the `Browse` button to navigate to `dnr_habs`.\nClick `Create project` and a new RStudio session will begin with the `dnr_habs` directory open.\n\nOn the command line, run `git status` and you'll notice that there are two new files added: `.gitignore` and `dnr_habs.Rproj`.\nWe'll talk about these more later, but let's commit this for now:\n\n1.  `git status` (Verify that `dnr_habs.Rproj` and `.gitignore` are untracked files)\n2.  `git add .` (Note the dot; we're adding all of the changes to all of the files in the current working directory)\n3.  `git commit -m 'Create RProject'`\n4.  `git push`\n\n::: {.callout-note appearance=\"simple\"}\n## Why use RProjects?\n\n`Rprojects` are a nice, simple way to keep all of your files related to a single project cleanly separated from other files on your system.\nIn addition, using an `Rproject` figures out your working directory for you; no need to `setwd` to get your scripts to work.\n\nTo get back here in the future, you can use `File > Open Project...`, or just open the `dnr_habs.Rproj` item.\n:::\n\n# Creating the document\n\nOkay, let's actually do some coding.\nIn RStudio, click `File > New File > Quarto Document...` and just go ahead and click `Create`.\nYou'll be taken to a new, empty document.\nThis document is in the Visual editor mode.\nFor now, click the \"Source\" button in the top left:\n\n![](../images/source_visual.png){fig-align=\"center\" width=\"600\"}\n\nGreat! Go ahead and save it as `dnr_eda.qmd`.\nFrom here we can start coding.\nWe'll start by loading the libraries we're going to use today.\nFirst, create a new code chunk.\nYou can select the \"+C\" button in the top right of the pane, or you can use the key shortcuts:\n\n-   On Mac, `Option + Command + I`\n-   On Windows, `Control + Alt + I`\n\nWithin the chunk, load `tidyverse`, `readxl`, `janitor`, and `lubridate`:\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\nlibrary(readxl)\nlibrary(lubridate)\nlibrary(janitor)\n\ntheme_set(theme_minimal())\n```\n:::\n\nGo ahead and run the chunk.\n\nNow we're ready to read the dataset.\n\n::: {.callout-note appearance=\"simple\"}\n## The Visual Markdown Editor\n\nThe Visual Markdown Editor is actually super sick and let's you do a lot of cool stuff.\nTo learn more about the Visual Editor, check out [the documentation](https://rstudio.github.io/visual-markdown-editing/).\n\nThe only reason I don't use it is because I use Vim keybindings in my RStudio, and those are not compatible with the Visual Markdown Editor.\n:::\n\n# Reading in the data\n\nBefore we can read in the data, we need to extract it from `DNR_data.zip` into the `data` folder.\nAfterwards, we can read in the data using `readxl`.\nWe'll start with the 2018 data.\nCreate a new code chunk, then run:\n\n::: {.cell}\n\n```{.r .cell-code}\ndnr.2018 <- read_xlsx(\"data/IowaDNR_2018_Data_Merged.xlsx\")\ndnr.2018 %>% \n  head()\n```\n:::\n\n::: {.cell}\n::: {.cell-output-stdout}\n```\n# A tibble: 6 × 17\n  Sample_ID   `Environmental Locati…` `Collected Date`    `Microcystin \\…`    pH\n  <chr>       <chr>                   <dttm>                         <dbl> <dbl>\n1 1-21280001  Backbone Beach          2018-05-22 11:19:00            0.63    8.1\n2 5-21280001  Backbone Beach          2018-06-19 09:00:00            0.46    8.8\n3 14-21280001 Backbone Beach          2018-08-21 13:00:00            0.438   8.9\n4 8-21280001  Backbone Beach          2018-07-10 11:15:00            0.425   8.2\n5 15-21280001 Backbone Beach          2018-08-28 12:30:00            0.418   8.8\n6 13-21280001 Backbone Beach          2018-08-14 10:30:00            0.405   8  \n# … with 12 more variables: `DOC(ppm)` <dbl>, `TKP (mg P/L)` <dbl>,\n#   `TKN (mg N/L)` <dbl>, `NH3 (mg N/L)` <chr>, `NOx (mg N/L)` <dbl>,\n#   `NO2 (mg N/L)` <chr>, `Cl (mg Cl/L)` <chr>, `SO4 mg SO4/L)` <chr>,\n#   `16S rRNA gene\\r\\n(copies/mL)` <dbl>,\n#   `MicrocystismcyA gene\\r\\n(copies/mL)` <dbl>,\n#   `AanabaenamcyA gene\\r\\n(copies/mL)` <dbl>,\n#   `PlanktothrixmcyA gene\\r\\n(copies/mL)` <dbl>\n```\n:::\n:::\n\nThe column names are a little hard to work with.\nLet's use `janitor::clean_names` to make the column names easier to type:\n\n::: {.cell}\n\n```{.r .cell-code}\ndnr.2018 <- read_xlsx(\"data/IowaDNR_2018_Data_Merged.xlsx\") %>% \n  clean_names()\ndnr.2018 %>% \n  head()\n```\n:::\n\n::: {.cell}\n::: {.cell-output-stdout}\n```\n# A tibble: 6 × 17\n  sample_id  environmental_l… collected_date      microcystin_raw…   p_h doc_ppm\n  <chr>      <chr>            <dttm>                         <dbl> <dbl>   <dbl>\n1 1-21280001 Backbone Beach   2018-05-22 11:19:00            0.63    8.1    5.85\n2 5-21280001 Backbone Beach   2018-06-19 09:00:00            0.46    8.8    1.45\n3 14-212800… Backbone Beach   2018-08-21 13:00:00            0.438   8.9    2.15\n4 8-21280001 Backbone Beach   2018-07-10 11:15:00            0.425   8.2    1.91\n5 15-212800… Backbone Beach   2018-08-28 12:30:00            0.418   8.8    1.73\n6 13-212800… Backbone Beach   2018-08-14 10:30:00            0.405   8      1.50\n# … with 11 more variables: tkp_mg_p_l <dbl>, tkn_mg_n_l <dbl>,\n#   nh3_mg_n_l <chr>, n_ox_mg_n_l <dbl>, no2_mg_n_l <chr>, cl_mg_cl_l <chr>,\n#   so4_mg_so4_l <chr>, x16s_r_rna_gene_copies_m_l <dbl>,\n#   microcystismcy_a_gene_copies_m_l <dbl>,\n#   aanabaenamcy_a_gene_copies_m_l <dbl>,\n#   planktothrixmcy_a_gene_copies_m_l <dbl>\n```\n:::\n:::\n\nOkay, it's a bit easier to work with now.\n\n# Some EDA\n\n## Checking year counts\n\nLet's start off by counting the samples by year to make sure that the dataset doesn't have any observations from other years.\nSince `collected_date` is a datetime object (as denoted by the `dttm` beneath the column name), we can use the `year` function from `lubridate` to `count`:\n\n::: {.cell}\n\n```{.r .cell-code}\ndnr.2018 %>% \n  count(year(collected_date))\n```\n\n::: {.cell-output-stdout}\n```\n# A tibble: 2 × 2\n  `year(collected_date)`     n\n                   <dbl> <int>\n1                   2018   539\n2                     NA     1\n```\n:::\n:::\n\nIt looks like there's an observation that doesn't have the year for some reason.\nLet's take a look at it:\n\n::: {.cell}\n\n```{.r .cell-code}\ndnr.2018 %>% \n  filter(is.na(collected_date))\n```\n\n::: {.cell-output-stdout}\n```\n# A tibble: 1 × 17\n  sample_id  environmental_l… collected_date microcystin_raw_valu…   p_h doc_ppm\n  <chr>      <chr>            <dttm>                         <dbl> <dbl>   <dbl>\n1 4-21070001 George Wyth Bea… NA                                NA    NA      NA\n# … with 11 more variables: tkp_mg_p_l <dbl>, tkn_mg_n_l <dbl>,\n#   nh3_mg_n_l <chr>, n_ox_mg_n_l <dbl>, no2_mg_n_l <chr>, cl_mg_cl_l <chr>,\n#   so4_mg_so4_l <chr>, x16s_r_rna_gene_copies_m_l <dbl>,\n#   microcystismcy_a_gene_copies_m_l <dbl>,\n#   aanabaenamcy_a_gene_copies_m_l <dbl>,\n#   planktothrixmcy_a_gene_copies_m_l <dbl>\n```\n:::\n:::\n\nFor some reason, this observation has no data, but has a sample_id and location.\nChecking the original Excel file confirms that this is the case, and so we can remove this row as an additional step when we read in the file.\nThe updated command to read in the file is:\n\n::: {.cell}\n\n```{.r .cell-code}\ndnr.2018 <- read_xlsx(\"data/IowaDNR_2018_Data_Merged.xlsx\") %>% \n  clean_names() %>% \n  filter(!is.na(collected_date))\ndnr.2018 %>% \n  head()\n```\n:::\n\n::: {.cell}\n::: {.cell-output-stdout}\n```\n# A tibble: 6 × 17\n  sample_id  environmental_l… collected_date      microcystin_raw…   p_h doc_ppm\n  <chr>      <chr>            <dttm>                         <dbl> <dbl>   <dbl>\n1 1-21280001 Backbone Beach   2018-05-22 11:19:00            0.63    8.1    5.85\n2 5-21280001 Backbone Beach   2018-06-19 09:00:00            0.46    8.8    1.45\n3 14-212800… Backbone Beach   2018-08-21 13:00:00            0.438   8.9    2.15\n4 8-21280001 Backbone Beach   2018-07-10 11:15:00            0.425   8.2    1.91\n5 15-212800… Backbone Beach   2018-08-28 12:30:00            0.418   8.8    1.73\n6 13-212800… Backbone Beach   2018-08-14 10:30:00            0.405   8      1.50\n# … with 11 more variables: tkp_mg_p_l <dbl>, tkn_mg_n_l <dbl>,\n#   nh3_mg_n_l <chr>, n_ox_mg_n_l <dbl>, no2_mg_n_l <chr>, cl_mg_cl_l <chr>,\n#   so4_mg_so4_l <chr>, x16s_r_rna_gene_copies_m_l <dbl>,\n#   microcystismcy_a_gene_copies_m_l <dbl>,\n#   aanabaenamcy_a_gene_copies_m_l <dbl>,\n#   planktothrixmcy_a_gene_copies_m_l <dbl>\n```\n:::\n:::\n\nLet's count again to confirm this works:\n\n::: {.cell}\n\n```{.r .cell-code}\ndnr.2018 %>% \n  count(year(collected_date))\n```\n\n::: {.cell-output-stdout}\n```\n# A tibble: 1 × 2\n  `year(collected_date)`     n\n                   <dbl> <int>\n1                   2018   539\n```\n:::\n:::\n\nGreat!\nNow all of the remaining data has the correct year.\n\n## Exploring microcystin\n\nSince the microcystin concentration is how we're going to label the samples, we need to check that they're all there. \nSimilar to the above, we can count the number of missing rows using `is.na` and `count`:\n\n::: {.cell}\n\n```{.r .cell-code}\ndnr.2018 %>% \n  count(is.na(microcystin_raw_value_ug_l))\n```\n\n::: {.cell-output-stdout}\n```\n# A tibble: 1 × 2\n  `is.na(microcystin_raw_value_ug_l)`     n\n  <lgl>                               <int>\n1 FALSE                                 539\n```\n:::\n:::\n\nThis tells us that there are no missing values in the microcystin column, which is good since we won't need to throw any data away.\n\nNow let's see how the microcystin is distributed:\n\n::: {.cell}\n\n```{.r .cell-code}\ndnr.2018 %>% \n  ggplot(aes(microcystin_raw_value_ug_l)) +\n  geom_histogram(color = \"black\", fill = \"white\") +\n  labs(\n    x = \"Microcystin (ug/L)\",\n    y = \"Count\",\n    title = \"Microcystin concentration (all lakes, all weeks)\"\n  ) + \n  theme(\n    panel.grid.minor = element_blank(),\n    panel.grid.major.x = element_blank(),\n    plot.title = element_text(hjust = 0.5)\n  )\n```\n\n::: {.cell-output-display}\n![](getting_started_files/figure-html/unnamed-chunk-24-1.png){width=672}\n:::\n:::\n\nThe data shows a long right tail. This is our first hint that this is a highly imbalanced dataset.\n\n### Creating the `hazard_class` variable\n\nTo get a better idea of this, let's create a new class variable based on the microcystin concentration: if the microcystin is greater than 8 ug/L, we'll say that it is **hazardous**, and **safe** otherwise.\nFor now, let's just check print out the results and check that it works as we expected it to:\n\n::: {.cell}\n\n```{.r .cell-code}\ndnr.2018 %>% \n  mutate(hazard_class = if_else(\n    microcystin_raw_value_ug_l > 8,\n    \"hazardous\",\n    \"safe\"\n  )) %>% \n  select(microcystin_raw_value_ug_l, hazard_class)\n```\n\n::: {.cell-output-stdout}\n```\n# A tibble: 539 × 2\n   microcystin_raw_value_ug_l hazard_class\n                        <dbl> <chr>       \n 1                      0.63  safe        \n 2                      0.46  safe        \n 3                      0.438 safe        \n 4                      0.425 safe        \n 5                      0.418 safe        \n 6                      0.405 safe        \n 7                      0.39  safe        \n 8                      0.3   safe        \n 9                      0.237 safe        \n10                      0.205 safe        \n# … with 529 more rows\n```\n:::\n:::\n\nOkay, this looks correct. \nLet's update our code that reads in the data to include this before we forget:\n\n::: {.cell}\n\n```{.r .cell-code}\ndnr.2018 <- read_xlsx(\"data/IowaDNR_2018_Data_Merged.xlsx\") %>% \n  clean_names() %>% \n  filter(!is.na(collected_date)) %>% \n  mutate(hazard_class = if_else(\n    microcystin_raw_value_ug_l > 8,\n    \"hazardous\",\n    \"safe\"\n    ))\ndnr.2018 %>% \n  head()\n```\n:::\n\n::: {.cell}\n::: {.cell-output-stdout}\n```\n# A tibble: 6 × 18\n  sample_id  environmental_l… collected_date      microcystin_raw…   p_h doc_ppm\n  <chr>      <chr>            <dttm>                         <dbl> <dbl>   <dbl>\n1 1-21280001 Backbone Beach   2018-05-22 11:19:00            0.63    8.1    5.85\n2 5-21280001 Backbone Beach   2018-06-19 09:00:00            0.46    8.8    1.45\n3 14-212800… Backbone Beach   2018-08-21 13:00:00            0.438   8.9    2.15\n4 8-21280001 Backbone Beach   2018-07-10 11:15:00            0.425   8.2    1.91\n5 15-212800… Backbone Beach   2018-08-28 12:30:00            0.418   8.8    1.73\n6 13-212800… Backbone Beach   2018-08-14 10:30:00            0.405   8      1.50\n# … with 12 more variables: tkp_mg_p_l <dbl>, tkn_mg_n_l <dbl>,\n#   nh3_mg_n_l <chr>, n_ox_mg_n_l <dbl>, no2_mg_n_l <chr>, cl_mg_cl_l <chr>,\n#   so4_mg_so4_l <chr>, x16s_r_rna_gene_copies_m_l <dbl>,\n#   microcystismcy_a_gene_copies_m_l <dbl>,\n#   aanabaenamcy_a_gene_copies_m_l <dbl>,\n#   planktothrixmcy_a_gene_copies_m_l <dbl>, hazard_class <chr>\n```\n:::\n:::\n\nAnd now, let's see just how imbalanced these samples are:\n\n::: {.cell}\n\n```{.r .cell-code}\ndnr.2018 %>% \n  count(hazard_class) %>% \n  mutate()\n```\n\n::: {.cell-output-stdout}\n```\n# A tibble: 2 × 2\n  hazard_class     n\n  <chr>        <int>\n1 hazardous       17\n2 safe           522\n```\n:::\n:::\n\nSo, of the 539 total samples, only 17 of them are considered hazardous. \nTo put numbers on how imbalanced this is:\n\n::: {.cell}\n\n```{.r .cell-code}\ndnr.2018 %>% \n  group_by(hazard_class) %>% \n  summarise(n = n()) %>% \n  mutate(prop = n / sum(n))\n```\n\n::: {.cell-output-stdout}\n```\n# A tibble: 2 × 3\n  hazard_class     n   prop\n  <chr>        <int>  <dbl>\n1 hazardous       17 0.0315\n2 safe           522 0.968 \n```\n:::\n:::\n\nOnly **3%** of our samples belong to the minority class. \nThis is an **extremely** imbalanced dataset and we must address this when we do our model training and predictions.\n\n::: {.callout-note appearance=\"simple\"}\nNote that putting the microcystin on a log scale makes the distribution appear normal. \nThis is an example of a [log-normal distribution](https://en.wikipedia.org/wiki/Log-normal_distribution). Here is some further reading:\n\n* [A good post about its statistical properties](https://stats.stackexchange.com/questions/389315/what-is-the-best-point-forecast-for-lognormally-distributed-data)\n* [A post about making predictions on a log-normal distribution](https://stats.stackexchange.com/questions/155829/lognormal-regression)\n:::\n\n# Plotting counts of hazardous cases by lake\n\nThe next thing we might be interested in is *where* the HABs are occurring. \nThere are several ways to do this, but one way is to begin by filtering out the non-hazardous samples, then counting the locations the hazardous samples occurred at:\n\n::: {.cell}\n\n```{.r .cell-code}\ndnr.2018 %>% \n  filter(hazard_class == \"hazardous\") %>% \n  count(environmental_location)\n```\n\n::: {.cell-output-stdout}\n```\n# A tibble: 7 × 2\n  environmental_location        n\n  <chr>                     <int>\n1 Crandall's Beach              1\n2 Denison Beach                 1\n3 Green Valley Beach            3\n4 Lake Macbride Beach           1\n5 Lake of Three Fires Beach     3\n6 McIntosh Woods Beach          1\n7 Viking Lake Beach             7\n```\n:::\n:::\n\nSo this shows us that the harmful algal blooms occurred in only a few places.\nLet's make a plot to communicate this:\n\n::: {.cell}\n\n```{.r .cell-code}\ndnr.2018 %>% \n  filter(hazard_class == \"hazardous\") %>% \n  count(environmental_location) %>% \n  mutate(environmental_location = fct_reorder(environmental_location, n)) %>% \n  ggplot(aes(n, environmental_location)) + \n  geom_col() + \n  labs(\n    x = \"# Hazardous Samples\",\n    y = \"Sample Location\",\n    title = \"Nearly half of all HABs occurred at Viking Lake Beach in 2018\"\n  )\n```\n\n::: {.cell-output-display}\n![](getting_started_files/figure-html/unnamed-chunk-38-1.png){width=672}\n:::\n:::\n\n# Commit your work\n\nBefore we wrap up for the day, let's commit our work.\nWe're not making any webpages yet, so the only thing that we need to worry about is saving the `qmd` we've been working in.\nAfter that, go ahead and:\n\n1. `git status` (`data` and `dnr_eda.qmd` should show up here)\n2. `git add .`\n3. `git commit -m 'Begin EDA'`\n4. `git push`\n\nAfterwards, if you go to your Github page, you should see `dnr_eda.qmd` at the project root.\n\n# Homework \n\n* Repeat the EDA and visualizations for the 2019 data set.\n* Commit and push your changes\n* Combine the 2019 and 2020 datasets. \n\n# Next time\n\n* Model training and predictions with `tidymodels` ",
    "supporting": [
      "getting_started_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": [],
    "engineDependencies": {},
    "preserve": {},
    "postProcess": null
  }
}